{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install numpy pygame tqdm matplotlib ipywidgets pandas torch Pillow ipympl\n",
    "%pip install minedojo --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Setting up PyTorch for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from abc import ABC\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import minedojo\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "minedojo.tasks.ALL_PROGRAMMATIC_TASK_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from helpers.hunt_cow import HuntCowDenseRewardEnv\n",
    "\n",
    "# IMAGE_SIZE = (142,255)\n",
    "IMAGE_SIZE = (160,256)\n",
    "# env = minedojo.make(\"harvest_wool_with_shears_and_sheep\", image_size=(160, 256) )\n",
    "env = HuntCowDenseRewardEnv(\n",
    "    step_penalty=0.1,\n",
    "    nav_reward_scale=2,\n",
    "    attack_reward=10,\n",
    "    success_reward=100,\n",
    "    image_size=IMAGE_SIZE,\n",
    ")\n",
    "env.task_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the extra environment variables\n",
    "# env.set_env_var(\"MINEDOJO_HEADLESS\", \"1\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#https://docs.minedojo.org/sections/core_api/action_space.html\n",
    "act_space = env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "obs_space = env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def load_item_mapping_from_csv(file_path):\n",
    "    item_mapping = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip the header row if it exists\n",
    "        for row in reader:\n",
    "            item_name, _, item_id, item_id_2 = row  # Change this line to read the first and third columns\n",
    "            if item_id is None or item_id == '':\n",
    "                item_id = 10000 + len(item_mapping)\n",
    "            item_id = int(item_id)\n",
    "            if item_id_2 is not None:\n",
    "                item_id = item_id + 10000 * int(item_id_2)\n",
    "\n",
    "            item_mapping[item_name] = item_id\n",
    "            item_mapping[item_name.replace(\" \", \"_\")] = item_id\n",
    "            item_mapping[item_name.replace(\" \", \"_\").lower()] = item_id\n",
    "            item_mapping[item_name.replace(\" \", \"_\").upper()] = item_id\n",
    "            item_mapping[item_name.replace(\" \", \"_\").capitalize()] = item_id\n",
    "            item_mapping[item_name.replace(\" \", \"_\").lower().capitalize()] = item_id\n",
    "            item_mapping[item_name.replace(\" \", \"_\").upper().capitalize()] = item_id\n",
    "            item_mapping[item_id] = item_id\n",
    "    return item_mapping\n",
    "\n",
    "#\n",
    "# def minimizeIds(item_mapping):\n",
    "#     # minimizing IDs by replacing each items id with its index in the list\n",
    "#     # this is done to reduce the size of the observation space\n",
    "#     minimized = {}\n",
    "#     for key, value in item_mapping.items():\n",
    "#         if key not in minimized:\n",
    "#             minimized[key] = len(minimized)\n",
    "#     return minimized\n",
    "\n",
    "# ensure all numeric ids are unique\n",
    "# def check_item_mapping(item_mapping):\n",
    "#     numeric_ids = [item_id for item_id in item_mapping.values() if isinstance(item_id, int)]\n",
    "#     assert len(numeric_ids) == len(set(numeric_ids))\n",
    "\n",
    "string_to_index_mapping = load_item_mapping_from_csv(\"minecraft_items.csv\")\n",
    "\n",
    "# string_to_index_mapping = minimizeIds(string_to_index_mapping)\n",
    "\n",
    "# check_item_mapping(string_to_index_mapping)\n",
    "\n",
    "string_to_index_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "def preprocess_observation(obs_dict, space_dict = obs_space, string_to_index_mapping=string_to_index_mapping):\n",
    "    rgb = obs_dict['rgb']\n",
    "    equipment = obs_dict['equipment'][\"name\"]\n",
    "    equipment_count = obs_dict['equipment'][\"quantity\"]\n",
    "    inventory = obs_dict['inventory']['name']\n",
    "    inventory_count = obs_dict['inventory']['quantity']\n",
    "    block_names = obs_dict[\"voxels\"][\"block_name\"]\n",
    "    block_collidable = obs_dict[\"voxels\"][\"is_collidable\"]\n",
    "    tool_req = obs_dict[\"voxels\"][\"is_tool_not_required\"]\n",
    "    is_liquid = obs_dict[\"voxels\"][\"is_liquid\"]\n",
    "    is_solid = obs_dict[\"voxels\"][\"is_solid\"]\n",
    "    look_vector = obs_dict[\"voxels\"][\"cos_look_vec_angle\"]\n",
    "    cur_durability = obs_dict[\"equipment\"][\"cur_durability\"]\n",
    "    max_durability = obs_dict[\"equipment\"][\"max_durability\"]\n",
    "    inc_name_by_craft = obs_dict[\"delta_inv\"][\"inc_name_by_craft\"]\n",
    "    inc_quantity_by_craft = obs_dict[\"delta_inv\"][\"inc_quantity_by_craft\"]\n",
    "    inc_name_by_other = obs_dict[\"delta_inv\"][\"inc_name_by_other\"]\n",
    "    inc_quantity_by_other = obs_dict[\"delta_inv\"][\"inc_quantity_by_other\"]\n",
    "    dec_name_by_craft = obs_dict[\"delta_inv\"][\"dec_name_by_craft\"]\n",
    "    dec_quantity_by_craft = obs_dict[\"delta_inv\"][\"dec_quantity_by_craft\"]\n",
    "    dec_name_by_other = obs_dict[\"delta_inv\"][\"dec_name_by_other\"]\n",
    "    dec_quantity_by_other = obs_dict[\"delta_inv\"][\"dec_quantity_by_other\"]\n",
    "    life = obs_dict[\"life_stats\"][\"life\"]\n",
    "    oxygen = obs_dict[\"life_stats\"][\"oxygen\"]\n",
    "    armor = obs_dict[\"life_stats\"][\"armor\"]\n",
    "    food = obs_dict[\"life_stats\"][\"food\"]\n",
    "    saturation = obs_dict[\"life_stats\"][\"saturation\"]\n",
    "    is_sleeping = obs_dict[\"life_stats\"][\"is_sleeping\"]\n",
    "    xp = obs_dict[\"life_stats\"][\"xp\"]\n",
    "    pos = obs_dict[\"location_stats\"][\"pos\"]\n",
    "    damage_amount = obs_dict[\"damage_source\"][\"damage_amount\"]\n",
    "\n",
    "    # give us a 1d array of all this stuff smooshed into ints\n",
    "    obs_list = []\n",
    "\n",
    "    rgb_flattened = np.zeros((len(rgb[0]), len(rgb[0][0])), dtype=np.uint32)\n",
    "    for channel in rgb:\n",
    "        for idx, row in enumerate(channel):\n",
    "            for idx2, item in enumerate(row):\n",
    "                rgb_flattened[idx][idx2] = rgb_flattened[idx][idx2] << 8\n",
    "                rgb_flattened[idx][idx2] = rgb_flattened[idx][idx2] | item\n",
    "\n",
    "\n",
    "    for row in rgb_flattened:\n",
    "        for item in row:\n",
    "            obs_list.append(item)\n",
    "    for item in equipment:\n",
    "        obs_list.append(string_to_index_mapping[item])\n",
    "    for item in equipment_count:\n",
    "        obs_list.append(item)\n",
    "    for item in inventory:\n",
    "        obs_list.append(string_to_index_mapping[item])\n",
    "    for item in inventory_count:\n",
    "        obs_list.append(item)\n",
    "    for list in block_names:\n",
    "        for sub_list in list:\n",
    "            for item in sub_list:\n",
    "                obs_list.append(string_to_index_mapping[item])\n",
    "    block_collidable_int = 0\n",
    "    for item in block_collidable:\n",
    "        # 2 nested lists inside this, but we want to flatten them each to ints using bit shifting\n",
    "        for sub_list in item:\n",
    "            for sub_item in sub_list:\n",
    "                block_collidable_int = block_collidable_int << 1\n",
    "                block_collidable_int = block_collidable_int | sub_item\n",
    "    obs_list.append(block_collidable_int)\n",
    "    tool_req_int = 0\n",
    "    for item in tool_req:\n",
    "        # 2 nested lists inside this, but we want to flatten them each to ints using bit shifting\n",
    "        for sub_list in item:\n",
    "            for sub_item in sub_list:\n",
    "                tool_req_int = tool_req_int << 1\n",
    "                tool_req_int = tool_req_int | sub_item\n",
    "    obs_list.append(tool_req_int)\n",
    "    is_liquid_int = 0\n",
    "    for item in is_liquid:\n",
    "        # 2 nested lists inside this, but we want to flatten them each to ints using bit shifting\n",
    "        for sub_list in item:\n",
    "            for sub_item in sub_list:\n",
    "                is_liquid_int = is_liquid_int << 1\n",
    "                is_liquid_int = is_liquid_int | sub_item\n",
    "    obs_list.append(is_liquid_int)\n",
    "    is_solid_int = 0\n",
    "    for item in is_solid:\n",
    "        # 2 nested lists inside this, but we want to flatten them each to ints using bit shifting\n",
    "        for sub_list in item:\n",
    "            for sub_item in sub_list:\n",
    "                is_solid_int = is_solid_int << 1\n",
    "                is_solid_int = is_solid_int | sub_item\n",
    "    obs_list.append(is_solid_int)\n",
    "    for item in look_vector:\n",
    "        for sub_item in item:\n",
    "            for sub_sub_item in sub_item:\n",
    "                obs_list.append(sub_sub_item)\n",
    "\n",
    "    #Data type: numpy.float32\n",
    "    # Shape: (6,)\n",
    "    for item in cur_durability:\n",
    "        obs_list.append(item)\n",
    "\n",
    "    for item in max_durability:\n",
    "        obs_list.append(item)\n",
    "\n",
    "    for item in inc_name_by_craft:\n",
    "        obs_list.append(string_to_index_mapping[item])\n",
    "    for item in inc_quantity_by_craft:\n",
    "        obs_list.append(item)\n",
    "\n",
    "    for item in inc_name_by_other:\n",
    "        obs_list.append(string_to_index_mapping[item])\n",
    "    for item in inc_quantity_by_other:\n",
    "        obs_list.append(item)\n",
    "\n",
    "    for item in dec_name_by_craft:\n",
    "        obs_list.append(string_to_index_mapping[item])\n",
    "    for item in dec_quantity_by_craft:\n",
    "        obs_list.append(item)\n",
    "\n",
    "    for item in dec_name_by_other:\n",
    "        obs_list.append(string_to_index_mapping[item])\n",
    "    for item in dec_quantity_by_other:\n",
    "        obs_list.append(item)\n",
    "\n",
    "    for item in life:\n",
    "        obs_list.append(item)\n",
    "\n",
    "    for item in oxygen:\n",
    "        obs_list.append(item)\n",
    "\n",
    "    for item in armor:\n",
    "        obs_list.append(item)\n",
    "\n",
    "    for item in food:\n",
    "        obs_list.append(item)\n",
    "\n",
    "    for item in saturation:\n",
    "        obs_list.append(item)\n",
    "\n",
    "    obs_list.append(is_sleeping)\n",
    "\n",
    "    # for item in xp:\n",
    "    #     obs_list.append(item)\n",
    "    #\n",
    "    # #\n",
    "    # for item in pos:\n",
    "    #     obs_list.append(item)\n",
    "    #\n",
    "    # obs_list.append(damage_amount)\n",
    "\n",
    "\n",
    "\n",
    "    return np.array(obs_list, dtype=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_shape = preprocess_observation(env.reset()).shape[0]\n",
    "num_actions = env.action_space.nvec.tolist()\n",
    "REDUCED_ACTION_SPACE = True\n",
    "\n",
    "if REDUCED_ACTION_SPACE:\n",
    "    # Keep actions 0 -> 5\n",
    "    num_actions = env.action_space.nvec.tolist()[0:6]\n",
    "print(f\"Input shape: {input_shape} | Number of actions: {num_actions}\")\n",
    "#\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(env.action_space.no_op())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# log to file\n",
    "LOG_FILENAME = 'training.log'\n",
    "logging.basicConfig(filename=LOG_FILENAME,level=logging.DEBUG)\n",
    "logging.info('Starting training')\n",
    "\n",
    "def print(item):\n",
    "    pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # todo: Masks are still not being applied properly. The agent is masking too much and can only ever look up. Peek `training.log`\n",
    "# def mask_multidiscrete_probs(masks, multidiscrete_tensor):\n",
    "#     # detach all tensors from the graph\n",
    "#     multidiscrete_tensor = [t.detach().cpu() for t in multidiscrete_tensor]\n",
    "#     # Create a list of zero-filled tensors with the same shapes as multidiscrete_tensor\n",
    "#     result = [torch.zeros_like(t) for t in multidiscrete_tensor]\n",
    "\n",
    "#     for i, key in enumerate(masks.keys()):\n",
    "#         mask = masks[key]\n",
    "#         for j, is_enabled in enumerate(mask) :\n",
    "#             if is_enabled and i < len(multidiscrete_tensor) and j < len(multidiscrete_tensor[i]):\n",
    "#                 result[i][j] = multidiscrete_tensor[i][j]\n",
    "\n",
    "#     return result\n",
    "\n",
    "\n",
    "def get_args_mask_for_func_action(fun_act_idx) -> str:\n",
    "    if(fun_act_idx == 0):\n",
    "        return 'no-op'\n",
    "    elif(fun_act_idx == 1):\n",
    "        return 'use'\n",
    "    elif(fun_act_idx == 2):\n",
    "        return 'drop'\n",
    "    elif(fun_act_idx == 3):\n",
    "        return 'attack'\n",
    "    elif(fun_act_idx == 4):\n",
    "        return 'craft_smelt'\n",
    "    elif(fun_act_idx == 5):\n",
    "        return 'equip'\n",
    "    elif(fun_act_idx == 6):\n",
    "        return 'place'\n",
    "    elif(fun_act_idx == 7):\n",
    "        return 'destroy'\n",
    "    else:\n",
    "        return 'no-op'\n",
    "\n",
    "\n",
    "def any_valid_arg(mask):\n",
    "    # return true if any bool in mask is true, mask is 1d\n",
    "    return np.any(mask)\n",
    "\n",
    "example_probs = [np.random.rand(3), np.random.rand(3), np.random.rand(4), np.random.rand(25), np.random.rand(25), np.random.rand(8), np.random.rand(244), np.random.rand(36)]\n",
    "\n",
    "example_probs = [torch.from_numpy(p) for p in example_probs]\n",
    "\n",
    "def mask_apply(masks, multidiscrete_tensor, isRandom=False, returnProbs=False):\n",
    "    \"\"\"\n",
    "             apply masks as follows:\n",
    "              1. Determine functional action (index 5, mask 'action_type') (size 8 bools)\n",
    "                 - action for subsequent steps is argmax of non-false masked values\n",
    "              2. Determine if action takes args (index 5, mask 'action_arg') (size 8 bools)\n",
    "              3. Based on action type, pick the corresponding mask from:\n",
    "                 - 'equip'      (size 36 bools, corresponds to inventory slots)\n",
    "                 - 'place'      (size 36 bools, corresponds to inventory slots)\n",
    "                 - 'destroy'    (size 36 bools, corresponds to inventory slots)\n",
    "                 - 'craft_smelt'    (size 244 bools, corresponds to all craftable items)\n",
    "                 - no mask for other options\n",
    "    :param masks: a dict of np array of bools with keys corresponding to what is being masked, as described above\n",
    "    :param multidiscrete_tensor: list of tensors of probabilities for every possible action\n",
    "    :return: the choice made based on argmax applied to each tensor in multidiscrete_tensor after masking\n",
    "    \"\"\"\n",
    "    # detach all tensors from the graph\n",
    "    multidiscrete_tensor = [t.detach().cpu() for t in multidiscrete_tensor]\n",
    "    # Create a list of zero-filled tensors with the same shapes as multidiscrete_tensor\n",
    "    result = [torch.zeros_like(t) for t in example_probs]\n",
    "\n",
    "\n",
    "    for(i, t) in enumerate(multidiscrete_tensor):\n",
    "        for(j, p) in enumerate(t):\n",
    "            if REDUCED_ACTION_SPACE:\n",
    "                if i == 5:\n",
    "                    if j == 0:\n",
    "                        result[i][j] = p\n",
    "                    elif j == 3:\n",
    "                        result[i][j] = p\n",
    "                    else:\n",
    "                        result[i][j] = 0\n",
    "                else:\n",
    "                    result[i][j] = p\n",
    "            else:\n",
    "                result[i][j] = p\n",
    "\n",
    "    # Apply func mask to index 5\n",
    "    func_mask = masks['action_type']\n",
    "    print(func_mask)\n",
    "    for i, is_enabled in enumerate(func_mask):\n",
    "        if is_enabled and i < len(multidiscrete_tensor[5]):\n",
    "            if i > 3 and any_valid_arg(masks[get_args_mask_for_func_action(i)]):\n",
    "                result[5][i] = multidiscrete_tensor[5][i] if not isRandom else np.random.uniform() + 0.5\n",
    "            elif i <= 3:\n",
    "                result[5][i] = multidiscrete_tensor[5][i] if not isRandom else np.random.uniform() + 0.5\n",
    "    print(len(result[5]))\n",
    "    print(result[5])\n",
    "\n",
    "    func_act = torch.argmax(result[5])\n",
    "    print(f\"func_act: {func_act}\")\n",
    "    # check arg mask with the choice\n",
    "    args_mask = masks['action_arg']\n",
    "    print(args_mask)\n",
    "    if args_mask[func_act.item()]:\n",
    "        msk = masks[get_args_mask_for_func_action(func_act.item())]\n",
    "        idx_of_result_to_use = 6 if  get_args_mask_for_func_action(func_act.item()) == 'craft_smelt' else 7\n",
    "        for i, is_enabled in enumerate(msk):\n",
    "            if idx_of_result_to_use < len(multidiscrete_tensor):\n",
    "                if i < len(multidiscrete_tensor[idx_of_result_to_use]):\n",
    "                    if is_enabled:\n",
    "                        result[idx_of_result_to_use][i] = multidiscrete_tensor[idx_of_result_to_use][i] if not isRandom else np.random.uniform() + 0.5\n",
    "                    else:\n",
    "                        result[idx_of_result_to_use][i] = 0\n",
    "\n",
    "    # argmax all the things\n",
    "    if returnProbs:\n",
    "        return result\n",
    "    for i, t in enumerate(result):\n",
    "        result[i] = torch.argmax(t).item()\n",
    "    logging.debug(f\"Masked result: {result}\")\n",
    "    if(env.action_space.contains(result)):\n",
    "        return result\n",
    "    else:\n",
    "        logging.debug(f\"Masked result is not valid: {result}\")\n",
    "        res = env.action_space.no_op()\n",
    "        logging.debug(f\"Returning no-op instead: {res}\")\n",
    "        return env.action_space.no_op()\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dims):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        # self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.actor_branches = nn.ModuleList().to(self.device)\n",
    "        # Set the desired dimensions for reshaping\n",
    "\n",
    "        self.C, self.H, self.W = 1, 187, 220\n",
    "\n",
    "        self.actor_branches = nn.ModuleList().to(self.device)\n",
    "        for action_dim in action_dims:\n",
    "            self.actor_branches.append(nn.Sequential(\n",
    "                nn.Conv2d(self.C, 32, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(128,1, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Flatten(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(621, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, action_dim),\n",
    "                # dimension is now (128, action_dim). We want to have (action_dim).print\n",
    "            ).to(self.device))\n",
    "\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Conv2d(self.C, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128,1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(621, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.uniform_(m.weight, -0.1, 0.1)\n",
    "                nn.init.uniform_(m.bias, -0.1, 0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, state):\n",
    "        state = state.view( self.C, self.H, self.W) # Reshape the input to (batch_size, C, H, W)\n",
    "        print(f\"Input state shape: {state.shape}\")\n",
    "        action_probs = [branch(state)[0] for branch in self.actor_branches]\n",
    "        for i, probs in enumerate(action_probs):\n",
    "            print(f\"Action probs shape at index {i}: {probs.shape}\")\n",
    "        value = self.critic(state)\n",
    "        return action_probs, value\n",
    "\n",
    "    def choose_action(self, state, mask, epsilon=0.5):\n",
    "        state = torch.tensor(np.array([state]), dtype=torch.float).to(self.device)\n",
    "        state = state.unsqueeze(0)  # Add an extra dimension for the batch size\n",
    "        dist, _ = self.forward(state)\n",
    "        action_probs = dist\n",
    "        choosing_randomly = np.random.uniform() < epsilon\n",
    "        # Call mask_multidiscrete_probs to mask the action_probs\n",
    "        for i, probs in enumerate(action_probs):\n",
    "            print(f\"probs: {probs.shape} at index {i}\")\n",
    "        actions =  mask_apply(mask, action_probs, isRandom=choosing_randomly)\n",
    "        # Choose actions based on the masked action probabilities\n",
    "        # actions = [np.argmax(masked_action_probs[i]) for i in range(len(masked_action_probs))]\n",
    "        return actions\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, transitions, gamma=0.99, critic_coeff=0.5, entropy_coeff=0.01):\n",
    "        states, actions_list, rewards, next_states, masks, dones = zip(*transitions)\n",
    "\n",
    "        actions = torch.tensor(actions_list, dtype=torch.long).to(self.device)\n",
    "\n",
    "        states = torch.tensor(states, dtype=torch.float).to(self.device)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float).to(self.device)\n",
    "\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float).to(self.device)\n",
    "        dones = torch.tensor(dones, dtype=torch.float).to(self.device)\n",
    "\n",
    "        # Calculate the discounted rewards\n",
    "        discounted_rewards = []\n",
    "        for i in range(len(rewards)):\n",
    "            Gt = 0\n",
    "            pw = 0\n",
    "            for r in rewards[i:]:\n",
    "                Gt = Gt + gamma**pw * r\n",
    "                pw = pw + 1\n",
    "            discounted_rewards.append(Gt)\n",
    "        discounted_rewards = torch.tensor(discounted_rewards, dtype=torch.float).to(self.device)\n",
    "\n",
    "        # Calculate the advantage\n",
    "        _, critic_value = self.forward(states)\n",
    "        _, next_critic_value = self.forward(next_states)\n",
    "        advantage = discounted_rewards + gamma * next_critic_value.squeeze() * (1 - dones) - critic_value.squeeze()\n",
    "\n",
    "        # Calculate actor (policy) loss\n",
    "        action_probs, _ = self.forward(states)\n",
    "        actor_loss = 0\n",
    "        for i, action_prob in enumerate(action_probs):\n",
    "            log_probs = torch.log(action_prob)\n",
    "            log_probs = log_probs.gather(1, actions[:, i].unsqueeze(1))\n",
    "            actor_loss += (-log_probs * advantage.detach()).mean()\n",
    "        actor_loss /= len(action_probs)\n",
    "\n",
    "        # Calculate critic loss\n",
    "        _, critic_value = self.forward(states)\n",
    "        critic_loss = 0.5 * advantage.pow(2).mean()\n",
    "\n",
    "        # Calculate entropy loss\n",
    "        action_probs, _ = self.forward(states)\n",
    "        entropy = 0\n",
    "        for action_prob in action_probs:\n",
    "            entropy += (-action_prob * torch.log(action_prob)).mean()\n",
    "        entropy_loss = -entropy_coeff * entropy\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = actor_loss + critic_coeff * critic_loss + entropy_loss\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent = ActorCritic(input_shape, num_actions)\n",
    "print(num_actions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# increase batch size when we have a better model\n",
    "batch_size = 1\n",
    "num_epochs = 1000*15*15\n",
    "max_episode_steps = 850\n",
    "\n",
    "#\n",
    "# loaded = torch.load(\"model_68.pt\")\n",
    "# agent.load_state_dict(loaded)\n",
    "# save transitions to csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "with tqdm(total=num_epochs*batch_size*max_episode_steps) as pbar:\n",
    "    for epoch in range(num_epochs):\n",
    "        episode_rewards = []\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "\n",
    "        transitions = []\n",
    "\n",
    "        for episode in range(batch_size):\n",
    "            print(f\"Episode: {episode}\")\n",
    "            obs = env.reset()\n",
    "            state = preprocess_observation(obs)\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "\n",
    "            for step in range(max_episode_steps):\n",
    "                pbar.update(1)\n",
    "                masks = obs[\"masks\"]\n",
    "                print(\"chooosing action, stoooooooooge!\")\n",
    "                action = agent.choose_action(state, masks, epsilon=0.3)\n",
    "                print(f\"action: {[i for i in action]}\")\n",
    "                logging.info(f\"action: {[i for i in action]}\")\n",
    "                logging.info(f\"masks: {masks}\")\n",
    "                obs, reward, done, _ = env.step(action)\n",
    "                base_reward = reward\n",
    "                print(f\"reward: {reward}\")\n",
    "                # entities, distances = obs[\"rays\"][\"entity_name\"], obs[\"rays\"][\"entity_distance\"]\n",
    "                # sheep_idx = np.where(entities == \"sheep\")[0]\n",
    "                #\n",
    "                # if len(sheep_idx) > 0:\n",
    "                #     sheep_distance = np.min(distances[sheep_idx])\n",
    "                #     #encourage being closer to sheep\n",
    "                #     if sheep_distance < 8:\n",
    "                #         base_reward += 1 / (sheep_distance + 1)\n",
    "\n",
    "                next_state = preprocess_observation(obs)\n",
    "\n",
    "                episode_reward += base_reward\n",
    "                transitions.append((state, action, reward, next_state, masks, done))\n",
    "\n",
    "                if done:\n",
    "                    pbar.update(max_episode_steps - step)\n",
    "                    break\n",
    "\n",
    "                state = next_state\n",
    "\n",
    "            episode_rewards.append(episode_reward)\n",
    "\n",
    "        # Train the agent using collected transitions\n",
    "        agent.train(transitions)\n",
    "\n",
    "        mean_episode_reward = np.mean(episode_rewards)\n",
    "        torch.save(agent.state_dict(), f'model_{epoch}.pt')\n",
    "        logging.info(f\"Epoch: {epoch+1}/{num_epochs}, Mean Reward: {mean_episode_reward:.2f}, Epsilon: {0.5/(epoch+1)}\")\n",
    "        # print(f\"Epoch: {epoch+1}/{num_epochs}, Mean Reward: {mean_episode_reward:.2f}\")\n",
    "\n",
    "# save the model\n",
    "torch.save(agent.state_dict(), 'model.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
